{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2e2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95193206",
   "metadata": {},
   "source": [
    "##### Task 4\n",
    "\n",
    "### a) \n",
    "\n",
    "Since $B(t)$ is a $C^1$ function we know that it has to be continious and continious differentiable in the interval $t \\in [0, m]$. In other words $B(t)$ has to satisfy the following conditions\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "p_{3,i} = p_{0,i+1}, & \\forall \\; i = 1, \\ldots, m-1 \\\\\n",
    "p_{3,i} - p_{2,i} = p_{1,i+1} - p_{0,i+1},  & \\forall \\; i = 1, \\ldots, m-1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "From the equation above we observe that $p_{2,i}$ can be expressed as\n",
    "\n",
    "$$\n",
    "p_{2,i} = 2p_{0,i+1} - p_{1,i+1}\n",
    "$$\n",
    "\n",
    "We can try and phrase this information using the velocity $v_{i+1}$ at $p_{0,i+1}$. Using the results from $\\textbf{2c)}$ and the equation above we get that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "v_{i+1} &= c_{i+1}'(0) \\\\\n",
    "&= 3 (p_{1,i+1}-p_{0,i+1}) \\\\\n",
    "&= 3 \\left(p_{1,i+1} - \\frac{1}{2}(p_{2,i} +  p_{1,i+1})\\right) \\\\\n",
    "&= \\frac{3}{2}\\left(p_{1,i+1} - p_{2,i}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We observe that from this expression we can recover both ‚Äúneighboring‚Äù points $p_{2,i}$ and $p_{1,i+1}$.\n",
    "\n",
    "\n",
    "### b) \n",
    "\n",
    "We want to minimize the (squared) acceleration of the curve\n",
    "\n",
    "$$\n",
    "F(\\mathbf{P}) := \\int_0^m ||\\mathbf{B}''(t)||^2 dt,\n",
    "$$\n",
    "\n",
    "with respect to the remaining control points \n",
    "\n",
    "$$\n",
    "\\mathbf{P} = [p_{0,1},p_{1,1}, p_{0,2}, p_{1,2}, \\ldots , p_{0,m-1}, p_{1,m-1}, p_{0,m}, p_{1,m}, p_{2,m}, p_{3,m}].\n",
    "$$\n",
    "\n",
    "For simplicity we only consider one segment of the composite B√©zier curve for the points ($q_0$, $q_1$, $q_2$, $q_3$) $\\in \\mathbb{R}^2$; $b_3(t; q_0, q_1, q_2, q_3)$ and use this to find the gradient of \n",
    "\n",
    "$$\n",
    "\\tilde{F}(q_0,q_1,q_2,q_3) := \\int_0^1 ||b_3''(t;q_0, q_1, q_2, q_3)||_2^2 dt\n",
    "$$\n",
    "\n",
    "with respect to the control points $q_i$, $i = 0, \\ldots, 3$. From task $\\textbf{2c)}$ we recall that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "b_3''(t;q_0, q_1, q_2, q_3) &= 3 \\cdot 2 \\left[ \\sum_{i=0}^{3-2} B_{i,3-2}(t)\\left(q_{i+2} - 2q_{i+1} + q_{i}\\right) \\right] \\\\\n",
    "&= 6 \\left[ \\sum_{i=0}^{1} B_{i,1}(t)\\left(q_{i+2} - 2q_{i+1} + q_{i}\\right) \\right] \\\\\n",
    "&= 6 \\left[ B_{0,1}(t)(q_2 -2q_1 + q_0) + B_{1,1}(t)(q_3 -2q_2 + q_1)\\right] \\\\\n",
    "&= 6 \\left[ \\binom{1}{0}t^{0}(1-t)^{1-0}(q_2 -2q_1 + q_0) + \\binom{1}{1}t^{1}(1-t)^{1-1}(q_3 -2q_2 + q_1)\\right] \\\\\n",
    "&= 6 \\left[ (1-t)(q_2 - 2q_1 + q_0) + t(q_3 - 2q_2 + q_1)\\right] \\\\\n",
    "&= 6 \\left[ t(q_3 -3q_2 + 3q_1 - q_0) + q_2 -2q_1 + q_0 \\right] \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\tilde{F}(q_0,q_1,q_2,q_3) &:= \\int_0^1 ||b_3''(t;q_0, q_1, q_2, q_3)||_2^2 dt \\\\\n",
    "&= \\int_0^1 ||6 \\left[ t(q_3 -3q_2 + 3q_1 - q_0) + q_2 -2q_1 + q_0 \\right] ||_2^2 dt \\\\\n",
    "&= 36 \\int_0^1 \\left(t(q_3 -3q_2 + 3q_1 - q_0)+q_2 -2q_1 + q_0\\right)^2 dt \\\\,\n",
    "\\end{align*}\n",
    "$$\n",
    "we let $p = (q_3 -3q_2 + 3q_1 - q_0)$ and $r = (q_2 -2q_1 + q_0)$ and we obtain \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\tilde{F}(q_0,q_1,q_2,q_3) &:= 36 \\int_0^1 \\left(tp + r \\right)^2 dt \\\\\n",
    "&= 36 \\int_0^1 t^2 p^2+ 2tpr + r^2 dt \\\\\n",
    "&= 36 \\left[\\frac{1}{3} p^2 t^3 + prt^2  +r^2t\\right]_0^1 \\\\\n",
    "&= 36 \\left(\\frac{1}{3} p^2 + pr  +r^2\\right) \\\\\n",
    "&= 36 \\left(\\frac{1}{3} (q_3 -3q_2 + 3q_1 - q_0)^2 + (q_3 -3q_2 + 3q_1 - q_0)(q_2 -2q_1 + q_0) + (q_2 -2q_1 + q_0)^2 \\right)\\\\\n",
    "&= 12\\left( q_0^2-3q_1q_0 + q_3q_0 + 3q_1^2+3q_2^2+q_3^2-3q_1q_2-3q_2q_3 \\right),\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "and the gradient of $\\tilde{F}(q_0,q_1,q_2,q_3)$ is given by\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla \\tilde{F}(q_0,q_1,q_2,q_3) &= \\left( \\frac{\\partial \\tilde{F}}{\\partial q_0}, \\frac{\\partial \\tilde{F}}{\\partial q_1}, \\frac{\\partial \\tilde{F}}{\\partial q_2}, \\frac{\\partial \\tilde{F}}{\\partial q_3}\\right) \\\\\n",
    "&= 12\\left([2q_0-3q_1+q_3], [-3q_0+6q_1-3q_2], [-3q_1+6q_2-3q_3], [q_0 -3q_2+2q_3]\\right) \\\\\n",
    "&= 12\\begin{bmatrix} \n",
    "2 & -3 & 0 & 1 \\\\\n",
    "-3 & 6 & -3 & 0 \\\\\n",
    "0 & -3 & 6 & -3 \\\\\n",
    "1 & 0 & -3 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} q_0 \\\\ q_1 \\\\ q_2 \\\\ q3 \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We can use this result to compute the whole gradient of $F$ based on the compressed $\\mathbf{P} = [p_{0,1},p_{1,1},p_{0,2}, p_{1,2}, \\ldots , p_{0,m-1}, p_{1,m-1}, p_{0,m}, p_{1,m},p_{2,m}, p_{3,m}]$. From task $\\textbf{4a)}$ we know that the missing points in sequence $c_i$ for $i= 1,\\ldots, m-1$ can be expressed using the first two points in the next sequence. We obtain that $\\tilde{F}_i(p_{0,i}, p_{1,i},p_{2,i}, p_{3,i}) = \\tilde{F}_i(p_{0,i}, p_{1,i},2p_{0,i+1}-p_{1,i+1}, p_{0,i+1})$. Using this and the linearity of the $\\nabla$ operator we get that\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla F(p_{0,1}, p_{1,1}, \\ldots, p_{3,m}) &= \\left( \\frac{\\partial F}{\\partial p_{0,1}}, \\frac{\\partial F}{\\partial p_{1,1}}, \\ldots, \\frac{\\partial F}{\\partial p_{3,m}} \\right) \\\\\n",
    "&= \\left( \\frac{\\partial \\tilde{F_1}}{\\partial p_{0,1}}, \\frac{\\partial \\tilde{F_1}}{\\partial p_{1,1}}, \\ldots, \\frac{\\partial \\tilde{F_m}}{\\partial p_{3,m}} \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Task: \n",
    "While we do not want to write down the whole gradient of F, sketch how you can\n",
    "use the result of FÀú to compute the gradient of F. Remember that B(t) is continuously\n",
    "differentiable.\n",
    "\n",
    "\n",
    "### c) \n",
    "We try to solve the equation \n",
    "\n",
    "$$\n",
    "\\nabla \\tilde{F}(\\mathbf{q}^*) = 0\n",
    "$$\n",
    "\n",
    "then $\\mathbf{q}^*$ is a possible minimizer for $\\tilde{F}(\\mathbf{q})$. We use our calculated gradient from $\\textbf{4b)}$ and we get that\n",
    "\n",
    "$$\n",
    "\\nabla \\tilde{F}(\\mathbf{q^*}) = 12\\begin{bmatrix} \n",
    "2 & -3 & 0 & 1 \\\\\n",
    "-3 & 6 & -3 & 0 \\\\\n",
    "0 & -3 & 6 & -3 \\\\\n",
    "1 & 0 & -3 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "q^*_0 \\\\ q^*_1 \\\\ q^*_2 \\\\ q^*_3\n",
    "\\end{bmatrix}\n",
    "= \\vec{0}\n",
    "$$\n",
    "\n",
    "We reduce the matrix to row echolon form and obtain \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & -3 & 2\\\\\n",
    "0 & 1 & -2 & 1 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "q^*_0 \\\\ q^*_1 \\\\ q^*_2 \\\\ q^*_3\n",
    "\\end{bmatrix}\n",
    "= \\vec{0}\n",
    "$$\n",
    "\n",
    "From the row echolon representation above we observe that $q^*_2$ and $q^*_3$ are free variables. Which means that the solution to the equation $\\nabla \\tilde{F}(\\mathbf{q}^*) = 0$ has infinitly many solutions. We let $q^*_2 = r$ and $q^*_3 = s$ for any points $r,s \\in \\mathbb{R}^2$. Then the solution of  $\\tilde{F}(\\mathbf{q}^*) = 0$ is \n",
    "\n",
    "$$\n",
    "\\mathbf{q}^* = \\begin{bmatrix}q^*_0 \\\\ q^*_1 \\\\ q^*_2 \\\\ q^*_3\\end{bmatrix} = \\begin{bmatrix} 3r - 2s \\\\ 2r -s \\\\ r \\\\ s \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We observe from task $\\textbf{4b)}$ that $\\tilde{F}(\\mathbf{q}) \\geq 0$ for all $\\mathbf{q}$. We want to check if our $\\mathbf{q}^*$ is actually a minimizer for $\\tilde{F}(\\mathbf{q})$ and obtain:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&\\tilde{F}(3r-2s,2r-s,r,s) \\\\\n",
    "&= 36 \\left(\\frac{1}{3} (s -3r + 3(2r-s) - (3r-2s))^2 + (s -3r + 3(2r-s)- (3r-2s))(r -2(2r-s) + (3r-2s)) + (r -2(2r-s) + (3r-2s))^2 \\right)\\\\\n",
    "&= 36 \\left(\\frac{1}{3} (s-3s+2s -3r+6r-3r)^2 + (s-3s+2s -3r+6r-3r)(2s-2s + r-4r+3r) + (2s-2s +r-4r+3r)^2 \\right)\\\\\n",
    "&= 36 \\left( 0 + 0\\cdot 0 + 0 \\right) \\\\\n",
    "&= 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We observe from the result above that our $\\mathbf{q}^*$ is a global minimizer for the function $\\tilde{F}(q_0,q_1,q_2,q_3)$, since \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\tilde{F}(\\mathbf{q}^*) \\leq \\tilde{F}(\\mathbf{q}), &&\\forall \\mathbf{q}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "For the overall problem $F$ we have to take into account the properties of $C^1$ between the segments. For simplicity \n",
    "\n",
    "Task: \n",
    "For the overall problem F we even have to take into account the properties from the C^1\n",
    "property between the segments. What about the solution now? Is it unique? You may\n",
    "argue intuitively here or provide a concrete example of two minimisers for a 2-segment\n",
    "curve, i.e. m = 2.\n",
    "\n",
    "\n",
    "### d)\n",
    "\n",
    "We extend our problem to have some (data) points $\\mathbf{d}_i \\in \\mathbb{R}^2$, $i = 0,\\ldots m$ and we extend the problem to\n",
    "\n",
    "$$\n",
    "G_{\\lambda}(\\mathbf{P}) = \\frac{\\lambda}{2} \\sum_{i=0}^{m} ||\\mathbf{d}_i - \\mathbf{B}(i)||_2^2 + \\int_0^m ||\\mathbf{B}''(t)||_2^2 dt,\n",
    "$$\n",
    "\n",
    "for some $\\lambda > 0$. Again we want to look at the simple case when we only have two points $s,e \\in \\mathbb{R}^2$ and we get that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\tilde{G}_{\\lambda}(q_0,q_1,q_2,q_3) &= \\frac{\\lambda}{2} \\left(||s - b_3(0;q_0,q_1,q_2,q_3)||_2^2 + ||e - b_3(1;q_0,q_1,q_2,q_3)||_2^2\\right) + \\tilde{F}(q_0,q_1,q_2,q_3) \\\\\n",
    "&= \\frac{\\lambda}{2} \\left(||s - q_0||_2^2 + ||e - q_3||_2^2\\right) + \\tilde{F}(q_0,q_1,q_2,q_3) \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We recall that $\\tilde{F}(q_0,q_1,q_2,q_3)$ is given by\n",
    "\n",
    "$$\n",
    "\\tilde{F}(q_0,q_1,q_2,q_3) = 36 \\left[ |q_3 -3q_2 + 3q_1 - q_0|^2 + |q_2 -2q_1 + q_0|^2 \\right],\n",
    "$$\n",
    "\n",
    "and that $\\nabla \\tilde{F}(\\mathbf{q}^*) = 0$ had the solution \n",
    "\n",
    "$$\n",
    "\\mathbf{q}_\\tilde{F}^* = \\begin{bmatrix}q^*_0 \\\\ q^*_1 \\\\ q^*_2 \\\\ q^*_3\\end{bmatrix} = \\begin{bmatrix} 3a - 2b \\\\ 2a -b \\\\ a \\\\ b \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "for any points $a,b \\in \\mathbb{R}^2$.\n",
    "Now we will find a minimizer for $\\tilde{G}_{\\lambda}(q_0,q_1,q_2,q_3)$ and determine if this minimizer is unique. We directly see from the equations that $\\tilde{G}_{\\lambda}(q_0,q_1,q_2,q_3)$  has its global minima when $s = q_0$, $e = q_3$ and $\\mathbf{q} = \\mathbf{q}^*_{\\tilde{F}}$. Thus we get that \n",
    "\n",
    "$$\n",
    "\\mathbf{q}^*_{G_{\\lambda}}= \\begin{bmatrix} 3a - 2b \\\\ 2a -b \\\\ a \\\\ b \\end{bmatrix} = \\begin{bmatrix} s \\\\ 2a -b \\\\ a \\\\ e\\end{bmatrix} \n",
    "\\Rightarrow \\begin{cases} q_0 = s = 3a -2b \\\\ q_1 = 2a -b \\\\ q_2 = a \\\\ q_3 = e = b \\end{cases}\n",
    "\\Rightarrow \\begin{cases} a = \\frac{1}{3}(s+ 2e) \\\\ b= e \\end{cases}, \n",
    "$$\n",
    "\n",
    "and we obtain the unique minimizer \n",
    "\n",
    "$$\n",
    "\\mathbf{q}^*_{G_{\\lambda}} = \\begin{bmatrix} s \\\\ \\frac{2}{3}(s + 2e) - e \\\\ \\frac{1}{3}(s+ 2e) \\\\ e \\end{bmatrix} = \n",
    "\\begin{bmatrix} s \\\\ \\frac{1}{3}(2s + e) \\\\ \\frac{1}{3}(s + 2e) \\\\ e \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "If we let $\\lambda$ tend to zero in this model we ignore the first term of the equation and we get \n",
    "\n",
    "$$\n",
    "\\tilde{G}_{\\lambda}(q_0,q_1,q_2,q_3) = \\tilde{F}(q_0,q_1,q_2,q_3), \n",
    "$$\n",
    "\n",
    "and we loose the uniqueness since $\\tilde{F}(q_0,q_1,q_2,q_3)$ has not unique minimizer. When $\\lambda$ tend to $\\infty$ we get \n",
    "\n",
    "$$\n",
    "\\tilde{G}_{\\lambda}(q_0,q_1,q_2,q_3) = \\lim_{\\lambda\\to\\infty} \\frac{\\lambda}{2} \\left(||s - q_0||_2^2 + ||e - q_3||_2^2\\right) + \\tilde{F}(q_0,q_1,q_2,q_3) , \n",
    "$$\n",
    "\n",
    "and we observe that the equation has its global minima when $\\mathbf{q} = \\mathbf{q}^*_{G_{\\lambda}}$. We also observe that if $s \\neq q_0$ or $e \\neq q_3$  $\\tilde{G}_{\\lambda}(q_0,q_1,q_2,q_3)$ also tends to $\\infty$ as $\\lambda \\to \\infty$. \n",
    "\n",
    "For the bigger problem $G_{\\lambda}(\\mathbf{P})$ for $m+1$ (data) points we also have uniqueness. This can be shown by induction. \n",
    "\n",
    "$\\textbf{Proof}$: When we have two points we have allready shown that this results in a unique minimizer. For each point $\\mathbf{d}_i$ we add, we get another unique minimizer for the added sequence. Thus for $m+1$ points $\\mathbf{d}_i$ for $i = 0, \\ldots, m$ we have $m$ subsequences $\\tilde{G}_{\\lambda}(q_0,q_1,q_2,q_3)$ from $\\mathbf{d}_i \\to \\mathbf{d}_{i+1}$, $i = 0,\\ldots, m-1$ each with a unique solution. Since $G_{\\lambda}(\\mathbf{P})$ can be written as a linear combination of subsequences $\\tilde{G}_{\\lambda}(q_0,q_1,q_2,q_3)$ with unique minimizers, $G_{\\lambda}(\\mathbf{P})$ also need to have a unique minimizer.\n",
    "\n",
    "If we let $\\lambda \\to 0$ we loose the uniqueness of the minimizer since $G_{0}(\\mathbf{P}) : = F(\\mathbf{P})$ which do not have a unique minimizer. When $\\lambda \\to \\infty$  we still have a unique minimizer for $G_{\\lambda}(\\mathbf{P})$. But if some of the (data) points $\\mathbf{d}_i \\neq p_{0,i+1}$ for $i = 0, \\ldots, m-1$ or $\\mathbf{d}_m \\neq p_{3,m}$, then $G_{\\lambda}(\\mathbf{P})$ also tends to $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c15e5",
   "metadata": {},
   "source": [
    "### e) \n",
    "\n",
    "Now we want to find a gradient descent method to minimize our function $G_{\\lambda}(\\mathbf{P})$ where we use the $\\mathbf{P}$ from task $\\textbf{3)}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51ba0bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.        ]\n",
      " [-1.          0.33333333]\n",
      " [ 1.          0.        ]\n",
      " [ 1.         -0.33333333]\n",
      " [ 0.33333333 -1.        ]\n",
      " [ 0.         -1.        ]]\n",
      "[[ 12.   0.]\n",
      " [-24. -12.]\n",
      " [  0. -12.]\n",
      " [-12.  24.]\n",
      " [-12.   0.]\n",
      " [ 24.  12.]\n",
      " [-12. -24.]\n",
      " [  0.  12.]]\n",
      "[[ 12.   0.]\n",
      " [-24. -12.]\n",
      " [  0. -12.]\n",
      " [-12.  24.]\n",
      " [-12.   0.]\n",
      " [ 24.  12.]\n",
      " [-12. -24.]\n",
      " [  0.  12.]]\n",
      "(array([[ 0.58065569,  1.52921016],\n",
      "       [ 1.06022342,  1.45372845],\n",
      "       [ 1.53018607,  1.02683002],\n",
      "       [ 1.47205427,  0.67326451],\n",
      "       [ 1.07208621, -0.03041954],\n",
      "       [ 0.72642495, -0.37896773],\n",
      "       [ 0.37896773, -0.72642495],\n",
      "       [ 0.03041954, -1.07208621]]), 50)\n",
      "(array([[ 1.06250000e+00,  1.50000000e+00],\n",
      "       [ 1.32291667e+00,  1.41666667e+00],\n",
      "       [ 1.50000000e+00,  1.00000000e+00],\n",
      "       [ 1.41666667e+00,  6.66666667e-01],\n",
      "       [ 1.00000000e+00, -1.15729754e-15],\n",
      "       [ 6.66666667e-01, -3.33333333e-01],\n",
      "       [ 3.33333333e-01, -6.66666667e-01],\n",
      "       [ 2.15212463e-15, -1.00000000e+00]]), 100000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Takes parameters:\n",
    "# ùúÜ: parameter for G\n",
    "# P: remaining data points\n",
    "P = np.array([[-1, 0], [-1, 1 / 3], [0, 1], [1 / 3, 1], [1, 0], [1, -1 / 3], [1 / 3, -1], [0, -1]])  \n",
    "\n",
    "def gradient_F_tilde(q):\n",
    "    return 12*np.array([2*q[0]-3*q[1]+q[3], -3*q[0]+6*q[1]-3*q[2], -3*q[1]+6*q[2]-3*q[3], q[0] -3*q[2]+2*q[3]])\n",
    "\n",
    "def compress_P(P_full):\n",
    "    c_P = []\n",
    "    for i in range(0, len(P_full)-4, 4):\n",
    "        c_P.append(P_full[i])\n",
    "        c_P.append(P_full[i+1])\n",
    "    c_P.append(P_full[-4])\n",
    "    c_P.append(P_full[-3])\n",
    "    c_P.append(P_full[-2])\n",
    "    c_P.append(P_full[-1])\n",
    "    return np.array(c_P)\n",
    "\n",
    "\n",
    "def gradient_F(P):\n",
    "    gradient = np.zeros_like(P)\n",
    "    for i in range(0, len(P)-4,2):\n",
    "        g_F_tilde = gradient_F_tilde(np.array([P[i],P[i+1],2*P[i+2]-P[i+3], P[i+2]]))\n",
    "        gradient[i] = g_F_tilde[0]\n",
    "        gradient[i+1] = g_F_tilde[1]\n",
    "    g_F_tilde = gradient_F_tilde(np.array([P[-4],P[-3],P[-2], P[-1]]))\n",
    "    gradient[-4],gradient[-3], gradient[-2], gradient[-1]  = g_F_tilde[0], g_F_tilde[1], g_F_tilde[2], g_F_tilde[3]\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def gradient_G(D,P,ùúÜ): \n",
    "    gradient_G_F = gradient_F(P)\n",
    "    gradient_norm = np.zeros_like(P)\n",
    "    for i in range(0, len(P)-2,2):\n",
    "        gradient_norm[i] = ùúÜ*(P[i]-D[i])\n",
    "    gradient_norm[-1] = ùúÜ*(P[-1]-D[-1])\n",
    "    return gradient_norm + gradient_G_F\n",
    "\n",
    "def GD(P, ùúÜ, tol, maxiter):\n",
    "    D = P\n",
    "    ùõº = 0.01  # Step size\n",
    "    d = gradient_G(D,P,ùúÜ)\n",
    "    norm = np.linalg.norm(-d)\n",
    "    P_new = P + ùõº*d\n",
    "    it = 0\n",
    "    while it < maxiter:\n",
    "        d_new = -gradient_G(D, P_new,ùúÜ)\n",
    "        P_new += ùõº * d_new\n",
    "        norm = np.linalg.norm(-d_new)\n",
    "        it += 1\n",
    "    return P_new, it\n",
    "      \n",
    "print(compress_P(P))\n",
    "print(gradient_F(P))\n",
    "print(gradient_G(np.copy(P),P,2))\n",
    "\n",
    "print(GD(P, 2, 3, 50))\n",
    "print(GD(P, 2, 3, 100000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eceb9bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Returns value of second term\n",
    "# def F(P):\n",
    "#     n = len(P)\n",
    "#     sum_1 = 0\n",
    "#     sum_2 = 0\n",
    "#     for i in range(2, n - 2, 2):\n",
    "#         sum_1 += 6 * (P[i + 1] - P[i])\n",
    "#         sum_2 += 3 * (P[i] - P[i + 1])\n",
    "#     return 36 * (norm(-P[0] + 3 * P[1] + sum_1 - 3 * P[-2] + P[-1]) ** 2 + norm(P[0] - 2 * P[1] + sum_2 + P[-2]) ** 2)\n",
    "\n",
    "# #Returns value of G\n",
    "# def G(P, ùúÜ):\n",
    "#     #Norm of all the elements to p_{1,m-1}\n",
    "#     sum_norm = 0\n",
    "#     for i in range(0, int(len(P) // 2 - 1)):\n",
    "#         for j in range(len(P)):\n",
    "#             if i <= j < 2 * i:\n",
    "#                 sum_norm += norm(P[j] - P[i*2]) ** 2\n",
    "                \n",
    "#     #Adding the norm of the last elements\n",
    "#     sum_norm += norm(P[-4] - P[-1])**2 + norm(P[-3] - P[-1])**2 + norm(P[-2] - P[-1])**2\n",
    "#     return (ùúÜ / 2) * sum_norm + F(P)\n",
    "\n",
    "# def gradient_G(P,ùúÜ): \n",
    "#     d = np.zeros_like(P)\n",
    "#     P_plus_h = P.copy()\n",
    "#     h = 0.1\n",
    "#     for i in range(len(P)):\n",
    "#         for j in range(len(P[i])):\n",
    "#             P_plus_h[i][j] += h\n",
    "#             d[i][j] = (G(P_plus_h, ùúÜ) - G(P, ùúÜ))/ h  #Calculate appriximate gradient\n",
    "#     return d\n",
    "\n",
    "# #  Calculates the gradient descent for our points P\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# result, iterations = GD(P, ùúÜ=2, tol=1, maxiter = 6)\n",
    "# print(\"Result:\", result)\n",
    "# print(\"Iterations:\", iterations)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a9a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
